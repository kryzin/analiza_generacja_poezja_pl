{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: [Ach! rzucić sieci zdarte...]\n",
      "Author: Tristan Derème\n",
      "Poem:\n",
      "\n",
      "Poeta, Kondycja ludzkaAch! rzucić sieci zdarte, wędki i robaki,\n",
      "I te książki! Być prostym, jak wiejskie chłopaki,\n",
      "Być nie-smutnym, podrwiwać z mieszczuchów kataru,\n",
      "W chłodne wieczory brzdąkać, szczycić się gitarą,\n",
      "Na miłostkach poprzestać, nie wzdychać: niestety,\n",
      "Są szczęśliwi, gdy grube złożą triolety[1],\n",
      "Kiedy rymują: sągi-ongi, żonki-dżonki.\n",
      "Lecz czuć, że życie siecią jest gęstej koronki,\n",
      "Pod którą drga twarz obca, jej się, blady, boję…\n",
      "Wokół twej kiści nagiej wiją się powoje.\n",
      "\n",
      "\n",
      "Title: A co wam śpiewać\n",
      "Author: Maria Konopnicka\n",
      "Poem:\n",
      "A co wam śpiewać, laleczki?\n",
      "Bo umiem różne piosneczki:\n",
      "Takie piosneczki i pieśni,\n",
      "O jakich lalkom się nie śni!\n",
      "Umiem piosenki z nad łąki,\n",
      "Tak jak je nucą skowronki,\n",
      "Kiedy piórkami szaremi\n",
      "Pod niebo lecą od ziemi,\n",
      "Nad ziemią lecą i dzwonią,\n",
      "Nad polem naszem, nad błonią.\n",
      "Umiem piosenkę jaskółki,\n",
      "Gdy lata koło rzeczułki,\n",
      "I wdzięcznym głoskiem coś nuci,\n",
      "Czy się weseli, czy smuci,\n",
      "Albo na gniazdko gdy leci,\n",
      "I śpiewa do snu dla dzieci.\n",
      "Umiem piosenkę żniwiarzy,\n",
      "\n",
      "Gdy pot im ścieka po twarzy,\n",
      "A oni, brzęcząc w swe kosy,\n",
      "Tną żyto srebrne od rosy,\n",
      "I głos roznoszą daleki,\n",
      "Aż echo wtórzy od rzeki.\n",
      "A chcecie piosnek wieczoru,\n",
      "Gdy idą owce z ugoru,\n",
      "I krówka z rżyska łaciata…\n",
      "Gdy trzaska stary Jan z bata.\n",
      "A ponad wszystkiem fujarka\n",
      "Dźwięczy małego owczarka?\n",
      "\n",
      "O! u nas piosnek bez liku!\n",
      "\n",
      "Tyle, co kropel w strumyku,\n",
      "Tyle, co liści na drzewie,\n",
      "A skąd się biorą, nikt nie wie.\n",
      "Tak już w powietrzu ot płyną,\n",
      "Nad naszą wioską jedyną.\n",
      "Więc co wam śpiewać, laleczki?\n",
      "Bo umiem różne piosneczki —\n",
      "Takie piosneczki i pieśni,\n",
      "O jakich lalkom się nie śni!\n",
      "\n",
      "\n",
      "Title: Pieśń II, 3 (Aequam memento rebus in arduis...)\n",
      "Author: Horacy\n",
      "Poem:\n",
      "\n",
      "Śmierć, SpokójPomnij zachować umysł niezachwiany\n",
      "Pośród złych przygód i od animuszu\n",
      "Zbyt zuchwałego wśród pomyślnej zmiany\n",
      "Chroń się, gdyż umrzesz, Delliuszu[2];\n",
      "\n",
      "Umrzesz, czy smutny przeżyjesz czas cały,\n",
      "Czy na trawniku zacisznym zasiędziesz\n",
      "Na dni świąteczne i z piwnic wystały\n",
      "Swój falern[3] zapijać będziesz.\n",
      "Gdzie biała topol z sosną rozrośniętą\n",
      "Chętnie swe cienie gościnnie zespala,\n",
      "Gdzie wstrząsać brzegu kotliną wygiętą\n",
      "Pierzchliwa sili się fala —\n",
      "Tam rozkaż przynieść i wina, i wonie,\n",
      "I kwiaty róży, tak krótkiej trwałości,\n",
      "Póki wiek, mienie i trzech prządek dłonie\n",
      "Tej ci dozwolą radości.\n",
      "\n",
      "Bogactwo, PrzemijanieZiem skupowanych ustąpisz — i domu.\n",
      "I willi, którą żółty Tyber myje —\n",
      "Ustąpisz: bogactw spiętrzonych ogromu\n",
      "Dziedzic twój potem użyje.\n",
      "\n",
      "Czyś bogacz, plemię Inachusa[4] stare,\n",
      "Czyś biedak, wyszły z warstw najniższych łona —\n",
      "Nie ma różnicy: Śmierćpójdziesz na ofiarę\n",
      "Bezlitosnego Plutona[5].\n",
      "Wszyscy zdążamy tamże: wszystkim z urny\n",
      "Prędzej czy później jeden los wychodzi:\n",
      "I w kraj wiecznego wygnania pochmurny\n",
      "Na smutnej wyśle nas łodzi.\n",
      "\n",
      "\n",
      "Title: Pieśń I, 30 (O Venus regina Cnidi Paphique...)\n",
      "Author: Horacy\n",
      "Poem:\n",
      "O Wenus[2]! Knidu[3] i Pafii[4] królowo,\n",
      "Porzuć Cypr ulubiony i zstąp do świątyni[5],\n",
      "Gdzie Glycera[6], zwąc[7] ciebie, z kadzideł wciąż nową\n",
      "Ofiarę czyni.\n",
      "\n",
      "Młodość, MiłośćNiech śpieszy z tobą i syn z strzałą w ręku[8],\n",
      "I Gracje[9] z rozwianymi przepaski[10], Nimf[11] chóry,\n",
      "I młodość, co bez ciebie pozbawiona wdzięku —\n",
      "I sam Merkury[12].\n",
      "\n",
      "Title: A jednak ja nie wątpię - bo się pora zbliża\n",
      "Author: Juliusz Słowacki\n",
      "Poem:\n",
      "\n",
      "Bóg, Chrystus, Cierpienie, Ojczyzna, TrupA jednak ja nie wątpię — bo się pora zbliża,\n",
      "Że się to wielkie światło na niebie zapali,\n",
      "I Polski Ty, o Boże, nie odepniesz z krzyża,\n",
      "Aż będziesz wiedział, że się jako trup nie zwali.\n",
      "\n",
      "ŚmiechDzięki Ci więc, o Boże — że już byłeś blisko,\n",
      "A jeszcześ Twojej złotej nie odsłonił twarzy,\n",
      "Aleś nas, syny Twoje, dał na pośmiewisko,\n",
      "Byśmy rośli jak kłosy pod deszczem potwarzy.\n",
      "\n",
      "Takiej chwały od czasu, jak na wiatrach stoi\n",
      "Glob ziemski — na żadnego nie włożyłeś ducha,\n",
      "Że się cichości naszej cała ziemia boi\n",
      "I sądzi się, że wolna jak dziecko, a słucha.\n",
      "\n",
      "CiałoZaprawdę w ciałach naszych światłość jakaś wielka\n",
      "Balsamująca ciało — formy żywicielka,\n",
      "Uwiecznica… promienie swe dawała złote\n",
      "Przez alabastry ciała.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Fetch all books\n",
    "books_url = \"https://wolnelektury.pl/api/books/\"\n",
    "response = requests.get(books_url)\n",
    "books = response.json()\n",
    "\n",
    "# Step 2: Filter for genre \"Wiersz\"\n",
    "poems = [book for book in books if book.get(\"kinds\") == \"Liryka\"]\n",
    "\n",
    "# Step 3: Limit to the first 5 poems\n",
    "test_poems = poems[:5]\n",
    "\n",
    "# Step 4: Extract poem details\n",
    "for poem in test_poems:\n",
    "    title = poem.get(\"title\")\n",
    "    author = poem.get(\"author\")\n",
    "    details_url = poem.get(\"href\")  # Detailed info about the poem\n",
    "\n",
    "    # Fetch detailed info\n",
    "    details_response = requests.get(details_url)\n",
    "    details = details_response.json()\n",
    "\n",
    "    # Step 5: Get the HTML text\n",
    "    html_url = details.get(\"html\")  # Full text in HTML format\n",
    "    html_response = requests.get(html_url)\n",
    "    soup = BeautifulSoup(html_response.content, \"html.parser\")\n",
    "\n",
    "    # Extract the poem content (verses are typically in <div> tags)\n",
    "    poem_body = \"\\n\".join([line.get_text() for line in soup.find_all(\"div\", class_=\"verse\")])\n",
    "    poem_body_cleaned = re.sub(r\"\\[.*?\\]\", \"\", poem_body)\n",
    "\n",
    "    # Print the poem details\n",
    "    print(f\"Title: {title}\\nAuthor: {author}\\nPoem:\\n{poem_body_cleaned}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\karol\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased\\snapshots\\3f076fdb1ab68d5b2880cb87a0886f315b8146f8\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\karol\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased\\snapshots\\3f076fdb1ab68d5b2880cb87a0886f315b8146f8\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\karol\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased\\snapshots\\3f076fdb1ab68d5b2880cb87a0886f315b8146f8\\model.safetensors\n",
      "Loaded 177,853,440 parameters in the TF 2.0 model.\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file config.json from cache at C:\\Users\\karol\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased\\snapshots\\3f076fdb1ab68d5b2880cb87a0886f315b8146f8\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\karol\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased\\snapshots\\3f076fdb1ab68d5b2880cb87a0886f315b8146f8\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\karol\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased\\snapshots\\3f076fdb1ab68d5b2880cb87a0886f315b8146f8\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\karol\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased\\snapshots\\3f076fdb1ab68d5b2880cb87a0886f315b8146f8\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\karol\\.cache\\huggingface\\hub\\models--bert-base-multilingual-cased\\snapshots\\3f076fdb1ab68d5b2880cb87a0886f315b8146f8\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing themes for: [Ach! rzucić sieci zdarte...]\n",
      "Candidate themes and scores:\n",
      "  życie: 0.53\n",
      "  radość: 0.53\n",
      "  szczęście: 0.53\n",
      "  śmierć: 0.52\n",
      "  pokój: 0.52\n",
      "  miłość: 0.52\n",
      "  smutek: 0.51\n",
      "  wojna: 0.51\n",
      "  przyjaźń: 0.51\n",
      "  marzenia: 0.51\n",
      "  nadzieja: 0.50\n",
      "  czas: 0.50\n",
      "  tęsknota: 0.50\n",
      "  cierpienie: 0.50\n",
      "  rodzina: 0.50\n",
      "  wolność: 0.50\n",
      "  natura: 0.50\n",
      "  religia: 0.50\n",
      "  przemijanie: 0.50\n",
      "  samotność: 0.50\n",
      "\n",
      "Analyzing themes for: A co wam śpiewać\n",
      "Candidate themes and scores:\n",
      "  czas: 0.52\n",
      "  radość: 0.52\n",
      "  smutek: 0.51\n",
      "  miłość: 0.51\n",
      "  życie: 0.51\n",
      "  śmierć: 0.51\n",
      "  szczęście: 0.51\n",
      "  wojna: 0.51\n",
      "  nadzieja: 0.51\n",
      "  pokój: 0.51\n",
      "  przyjaźń: 0.50\n",
      "  rodzina: 0.50\n",
      "  marzenia: 0.50\n",
      "  tęsknota: 0.50\n",
      "  natura: 0.50\n",
      "  wolność: 0.50\n",
      "  religia: 0.50\n",
      "  cierpienie: 0.50\n",
      "  przemijanie: 0.50\n",
      "  samotność: 0.50\n",
      "\n",
      "Analyzing themes for: Pieśń II, 3 (Aequam memento rebus in arduis...)\n",
      "Candidate themes and scores:\n",
      "  przemijanie: 0.55\n",
      "  radość: 0.55\n",
      "  wojna: 0.54\n",
      "  śmierć: 0.54\n",
      "  czas: 0.53\n",
      "  smutek: 0.53\n",
      "  pokój: 0.53\n",
      "  szczęście: 0.53\n",
      "  miłość: 0.53\n",
      "  życie: 0.52\n",
      "  nadzieja: 0.52\n",
      "  przyjaźń: 0.52\n",
      "  wolność: 0.52\n",
      "  tęsknota: 0.52\n",
      "  marzenia: 0.51\n",
      "  cierpienie: 0.51\n",
      "  samotność: 0.51\n",
      "  rodzina: 0.50\n",
      "  natura: 0.50\n",
      "  religia: 0.50\n",
      "\n",
      "Analyzing themes for: Pieśń I, 30 (O Venus regina Cnidi Paphique...)\n",
      "Candidate themes and scores:\n",
      "  miłość: 0.56\n",
      "  radość: 0.54\n",
      "  śmierć: 0.54\n",
      "  życie: 0.54\n",
      "  wojna: 0.53\n",
      "  marzenia: 0.53\n",
      "  przyjaźń: 0.53\n",
      "  szczęście: 0.53\n",
      "  pokój: 0.53\n",
      "  czas: 0.53\n",
      "  nadzieja: 0.52\n",
      "  wolność: 0.52\n",
      "  smutek: 0.52\n",
      "  przemijanie: 0.52\n",
      "  cierpienie: 0.52\n",
      "  natura: 0.51\n",
      "  rodzina: 0.51\n",
      "  samotność: 0.51\n",
      "  religia: 0.51\n",
      "  tęsknota: 0.51\n",
      "\n",
      "Analyzing themes for: A jednak ja nie wątpię - bo się pora zbliża\n",
      "Candidate themes and scores:\n",
      "  wolność: 0.56\n",
      "  śmierć: 0.55\n",
      "  miłość: 0.55\n",
      "  radość: 0.55\n",
      "  życie: 0.55\n",
      "  czas: 0.54\n",
      "  wojna: 0.54\n",
      "  pokój: 0.54\n",
      "  cierpienie: 0.53\n",
      "  marzenia: 0.53\n",
      "  przyjaźń: 0.53\n",
      "  nadzieja: 0.53\n",
      "  szczęście: 0.53\n",
      "  tęsknota: 0.52\n",
      "  natura: 0.52\n",
      "  przemijanie: 0.52\n",
      "  samotność: 0.51\n",
      "  smutek: 0.51\n",
      "  religia: 0.51\n",
      "  rodzina: 0.50\n",
      "Saved 5 poems with themes to 'poems_with_themes.csv'!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define the Poem class\n",
    "class Poem:\n",
    "    def __init__(self, title, author, content):\n",
    "        self.title = title\n",
    "        self.author = author\n",
    "        self.content = content\n",
    "        self.themes = []\n",
    "\n",
    "    def add_theme(self, theme):\n",
    "        \"\"\"Add a theme to the poem if it isn't already present.\"\"\"\n",
    "        if theme not in self.themes:\n",
    "            self.themes.append(theme)\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Convert the poem object to a dictionary.\"\"\"\n",
    "        return {\n",
    "            \"Title\": self.title,\n",
    "            \"Author\": self.author,\n",
    "            \"Content\": self.content,\n",
    "            \"Themes\": \", \".join(self.themes)\n",
    "        }\n",
    "\n",
    "# Initialize the Hugging Face zero-shot classification pipeline with mBERT\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"bert-base-multilingual-cased\",\n",
    "    tokenizer=\"bert-base-multilingual-cased\"\n",
    ")\n",
    "\n",
    "# Comprehensive list of candidate themes\n",
    "candidate_labels = [\n",
    "    \"nadzieja\", \"szczęście\", \"smutek\", \"miłość\", \"natura\",\n",
    "    \"wojna\", \"pokój\", \"wolność\", \"cierpienie\", \"radość\",\n",
    "    \"samotność\", \"przyjaźń\", \"religia\", \"czas\", \"przemijanie\",\n",
    "    \"życie\", \"śmierć\", \"rodzina\", \"tęsknota\", \"marzenia\"\n",
    "]\n",
    "\n",
    "def extract_poem_text(poem_data):\n",
    "    \"\"\"\n",
    "    Extract the full poem text from poem_data.\n",
    "    Args:\n",
    "        poem_data (dict): The JSON object containing poem metadata.\n",
    "    Returns:\n",
    "        str: The cleaned text of the poem.\n",
    "    \"\"\"\n",
    "    # Step 1: Get the detailed poem data\n",
    "    details_url = poem_data.get(\"href\")\n",
    "    details_response = requests.get(details_url)\n",
    "    details = details_response.json()\n",
    "\n",
    "    # Step 2: Get the HTML link for the poem's text\n",
    "    html_url = details.get(\"html\")\n",
    "    html_response = requests.get(html_url)\n",
    "\n",
    "    # Step 3: Parse the HTML content\n",
    "    soup = BeautifulSoup(html_response.content, \"html.parser\")\n",
    "    poem_body = \"\\n\".join([line.get_text() for line in soup.find_all(\"div\", class_=\"verse\")])\n",
    "\n",
    "    # Step 4: Clean up the poem text\n",
    "    poem_body_cleaned = re.sub(r\"\\[.*?\\]\", \"\", poem_body)  # Remove annotations in square brackets\n",
    "\n",
    "    return poem_body_cleaned\n",
    "\n",
    "def analyze_themes(poem, candidate_labels):\n",
    "    \"\"\"\n",
    "    Analyze themes using zero-shot classification and add themes with score >0.6.\n",
    "    Args:\n",
    "        poem (Poem): The Poem object to analyze.\n",
    "        candidate_labels (list): List of possible themes to classify.\n",
    "    \"\"\"\n",
    "    # Perform zero-shot classification\n",
    "    result = classifier(poem.content, candidate_labels=candidate_labels, multi_label=True)\n",
    "\n",
    "    print(f\"\\nAnalyzing themes for: {poem.title}\")\n",
    "    print(\"Candidate themes and scores:\")\n",
    "    for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "        print(f\"  {label}: {score:.2f}\")\n",
    "\n",
    "    # Add themes with scores > 0.6 to the poem\n",
    "    for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "        if score > 0.6:\n",
    "            poem.add_theme(label)\n",
    "\n",
    "# Main script logic\n",
    "# Step 1: Fetch all books\n",
    "# books_url = \"https://wolnelektury.pl/api/books/\"\n",
    "# response = requests.get(books_url)\n",
    "# books = response.json()\n",
    "\n",
    "# Step 2: Filter for genre \"Wiersz\"\n",
    "poems_data = [book for book in books if book.get(\"genre\") == \"Wiersz\"]\n",
    "\n",
    "# Step 3: Limit to the first 5 poems for testing\n",
    "test_poems = poems_data[:5]\n",
    "\n",
    "# Step 4: Process poems and analyze themes\n",
    "poems = []\n",
    "\n",
    "for poem_data in test_poems:\n",
    "    title = poem_data.get(\"title\")\n",
    "    author = poem_data.get(\"author\")\n",
    "    content = extract_poem_text(poem_data)\n",
    "\n",
    "    # Create a Poem object\n",
    "    poem = Poem(title=title, author=author, content=content)\n",
    "\n",
    "    # Analyze and add themes\n",
    "    analyze_themes(poem, candidate_labels)\n",
    "\n",
    "    poems.append(poem)\n",
    "\n",
    "# Step 5: Save poems to a CSV file\n",
    "import csv\n",
    "\n",
    "def save_poems_to_csv(poems, filename=\"poems_with_themes.csv\"):\n",
    "    \"\"\"Save a list of poems to a CSV file.\"\"\"\n",
    "    with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Title\", \"Author\", \"Content\", \"Themes\"])\n",
    "        writer.writeheader()\n",
    "        for poem in poems:\n",
    "            writer.writerow(poem.to_dict())\n",
    "\n",
    "save_poems_to_csv(poems)\n",
    "\n",
    "print(f\"Saved {len(poems)} poems with themes to 'poems_with_themes.csv'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'poems.db' has been initialized.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_name = \"poems.db\"\n",
    "\n",
    "def initialize_database():\n",
    "    \"\"\"Create a new SQLite database and initialize the poems table.\"\"\"\n",
    "    conn = sqlite3.connect(db_name)  # Create or connect to the database\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create the poems table\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS poems (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            title TEXT NOT NULL,\n",
    "            author TEXT NOT NULL,\n",
    "            content TEXT NOT NULL,\n",
    "            themes TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()  # Save changes\n",
    "    conn.close()  # Close the connection\n",
    "\n",
    "# Call the function to initialize the database\n",
    "initialize_database()\n",
    "print(f\"Database '{db_name}' has been initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4051\n",
      "Skipping poem: Noc bezsenna (cykl) - No content available.\n",
      "Saved all poems to poems.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pdfplumber\n",
    "\n",
    "# Function to fetch and clean the poem content\n",
    "def fetch_poem_data(poem_data):\n",
    "    title = poem_data.get(\"title\")\n",
    "    author = poem_data.get(\"author\")\n",
    "    details_url = poem_data.get(\"href\")\n",
    "\n",
    "    # Fetch detailed info\n",
    "    details_response = requests.get(details_url)\n",
    "    details = details_response.json()\n",
    "\n",
    "    # Get the HTML content of the poem\n",
    "    html_url = details.get(\"html\")\n",
    "    if html_url:\n",
    "        html_response = requests.get(html_url)\n",
    "        soup = BeautifulSoup(html_response.content, \"html.parser\")\n",
    "        poem_body = \"\\n\".join([line.get_text() for line in soup.find_all(\"div\", class_=\"verse\")])\n",
    "        poem_body_cleaned = re.sub(r\"\\[.*?\\]\", \"\", poem_body)\n",
    "    else:\n",
    "        # Fallback to PDF\n",
    "        pdf_url = details.get(\"pdf\")\n",
    "        if pdf_url:\n",
    "            pdf_response = requests.get(pdf_url)\n",
    "            with open(\"temp_poem.pdf\", \"wb\") as pdf_file:\n",
    "                pdf_file.write(pdf_response.content)\n",
    "            with pdfplumber.open(\"temp_poem.pdf\") as pdf_doc:\n",
    "                poem_body = \"\"\n",
    "                for page in pdf_doc.pages:\n",
    "                    poem_body += page.extract_text()\n",
    "            poem_body_cleaned = re.sub(r\"\\[.*?\\]\", \"\", poem_body.strip())\n",
    "        else:\n",
    "            # Fallback to TXT\n",
    "            txt_url = details.get(\"txt\")\n",
    "            if txt_url:\n",
    "                print(f\"Fetching poem content from TXT for: {details.get('title')}\")\n",
    "                txt_response = requests.get(txt_url)\n",
    "                poem_body_cleaned = re.sub(r\"\\[.*?\\]\", \"\", txt_response.text.strip())\n",
    "            else: poem_body_cleaned = None\n",
    "\n",
    "    # Return cleaned data\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"author\": author,\n",
    "        \"content\": poem_body_cleaned\n",
    "    }\n",
    "\n",
    "# Step 1: Fetch all books\n",
    "# books_url = \"https://wolnelektury.pl/api/books/\"\n",
    "# response = requests.get(books_url)\n",
    "# books = response.json()\n",
    "\n",
    "# Step 2: Filter for genre \"Wiersz\"\n",
    "poems_data = [book for book in books if book.get(\"genre\") == \"Wiersz\"]\n",
    "print(len(poems_data))\n",
    "# Step 3: Limit to the first 5 poems for testing\n",
    "test_poems = poems_data\n",
    "\n",
    "# Step 4: Extract data and save to CSV\n",
    "csv_filename = \"poems.csv\"\n",
    "with open(csv_filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\"Title\", \"Author\", \"Content\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for poem_data in test_poems:\n",
    "        poem = fetch_poem_data(poem_data)\n",
    "\n",
    "        if poem is None or poem[\"content\"] is None:\n",
    "            print(f\"Skipping poem: {poem_data.get('title')} - No content available.\")\n",
    "            continue\n",
    "\n",
    "        writer.writerow({\n",
    "            \"Title\": poem[\"title\"],\n",
    "            \"Author\": poem[\"author\"],\n",
    "            \"Content\": poem[\"content\"]\n",
    "        })\n",
    "\n",
    "print(f\"Saved all poems to {csv_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\compat\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     is_numpy_dev,\n\u001b[0;32m     20\u001b[0m     np_version_under1p21,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[0;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[0;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\util\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     Appender,\n\u001b[0;32m      4\u001b[0m     Substitution,\n\u001b[0;32m      5\u001b[0m     cache_readonly,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     hash_array,\n\u001b[0;32m     10\u001b[0m     hash_pandas_object,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     Any,\n\u001b[0;32m      8\u001b[0m     Callable,\n\u001b[0;32m      9\u001b[0m     Mapping,\n\u001b[0;32m     10\u001b[0m     cast,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     F,\n\u001b[0;32m     17\u001b[0m     T,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\_libs\\__init__.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m ]\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     NaT,\n\u001b[0;32m     16\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     iNaT,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\_libs\\interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = \"poems.csv\"  # Replace with your CSV filename\n",
    "df = pd.read_csv(csv_file)\n",
    "# test\n",
    "df = df.iloc[:5]\n",
    "\n",
    "# Comprehensive candidate labels\n",
    "candidate_labels = [\n",
    "    \"smutek\", \"miłość\", \"natura\",\n",
    "    \"wojna\", \"pokój\", \"wolność\", \"cierpienie\", \"radość\",\n",
    "    \"samotność\", \"przyjaźń\", \"przemijanie\",\n",
    "    \"życie\", \"śmierć\", \"tęsknota\",\n",
    "    \"dzieciństwo\", \"ojczyzna\", \"wiara\",\n",
    "    \"macierzyństwo\", \"poświęcenie\", \"przemiana\",\n",
    "    \"zemsta\", \"przywiązanie\"\n",
    "]\n",
    "\n",
    "def truncate_text(text, max_length=512):\n",
    "    tokens = text.split()  # Split text into tokens (words)\n",
    "    return \" \".join(tokens[:max_length])  # Truncate and rejoin tokens\n",
    "\n",
    "\n",
    "# Load the model and pipeline with GPU support\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_name, device=0)  # device=0 for GPU\n",
    "\n",
    "# Function to classify a batch of texts\n",
    "def classify_batch(batch_texts, classifier_pipeline, candidate_labels):\n",
    "    truncated_texts = [truncate_text(text) for text in batch_texts]  # Apply truncation\n",
    "\n",
    "    with autocast():\n",
    "        results = classifier_pipeline(batch_texts, candidate_labels=candidate_labels, multi_label=True)\n",
    "    batch_labels = []\n",
    "    for result in results:\n",
    "        # Filter labels with scores > 0.75\n",
    "        filtered_labels = [\n",
    "            label for label, score in zip(result[\"labels\"], result[\"scores\"]) if score > 0.75\n",
    "        ]\n",
    "        batch_labels.append(\", \".join(filtered_labels))\n",
    "    return batch_labels\n",
    "\n",
    "# Batch size for RTX 3060 (adjust if needed)\n",
    "batch_size = 16\n",
    "\n",
    "# Prepare results storage\n",
    "classified_poems = []\n",
    "\n",
    "# Process in batches\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df.iloc[i:i+batch_size]  # Get a batch of poems\n",
    "    batch_texts = batch[\"Content\"].tolist()\n",
    "\n",
    "    print(f\"Classifying batch {i // batch_size + 1} of {len(df) // batch_size + 1}...\")\n",
    "\n",
    "    # Classify the batch\n",
    "    batch_results = classify_batch(batch_texts, classifier, candidate_labels)\n",
    "\n",
    "    # Append results to classified_poems\n",
    "    for idx, poem in batch.iterrows():\n",
    "        poem_results = {\n",
    "            \"Title\": poem[\"Title\"],\n",
    "            \"Author\": poem[\"Author\"],\n",
    "            \"mDeBERTa-v3\": batch_results[idx - i]  # Map back to batch results\n",
    "        }\n",
    "        classified_poems.append(poem_results)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(classified_poems)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_csv = \"classification_results_by_model.csv\"\n",
    "results_df.to_csv(results_csv, index=False)\n",
    "\n",
    "print(f\"Filtered classification results saved to {results_csv}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute '_format_native_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[0;32m     18\u001b[0m csv_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification_results_by_model.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mresults_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m         warnings.warn(\n\u001b[0;32m    327\u001b[0m             msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m             FutureWarning,\n\u001b[0;32m    329\u001b[0m             stacklevel=find_stack_level(),\n\u001b[0;32m    330\u001b[0m         )\n\u001b[0;32m    331\u001b[0m     return func(*args, **kwargs)\n\u001b[1;32m--> 333\u001b[0m # error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\n\u001b[0;32m    334\u001b[0m # attribute \"__signature__\"\n\u001b[0;32m    335\u001b[0m wrapper.__signature__ = new_sig  # type: ignore[attr-defined]\n\u001b[0;32m    336\u001b[0m return wrapper\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3908\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   3909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mxs\u001b[39m(\n\u001b[0;32m   3910\u001b[0m     \u001b[38;5;28mself\u001b[39m: NDFrameT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3914\u001b[0m     drop_level: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3915\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3916\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3917\u001b[0m \u001b[38;5;124;03m    Return cross-section from the Series/DataFrame.\u001b[39;00m\n\u001b[0;32m   3918\u001b[0m \n\u001b[0;32m   3919\u001b[0m \u001b[38;5;124;03m    This method takes a `key` argument to select data at a particular\u001b[39;00m\n\u001b[0;32m   3920\u001b[0m \u001b[38;5;124;03m    level of a MultiIndex.\u001b[39;00m\n\u001b[0;32m   3921\u001b[0m \n\u001b[0;32m   3922\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   3923\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   3924\u001b[0m \u001b[38;5;124;03m    key : label or tuple of label\u001b[39;00m\n\u001b[0;32m   3925\u001b[0m \u001b[38;5;124;03m        Label contained in the index, or partially in a MultiIndex.\u001b[39;00m\n\u001b[0;32m   3926\u001b[0m \u001b[38;5;124;03m    axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39;00m\n\u001b[0;32m   3927\u001b[0m \u001b[38;5;124;03m        Axis to retrieve cross-section on.\u001b[39;00m\n\u001b[0;32m   3928\u001b[0m \u001b[38;5;124;03m    level : object, defaults to first n levels (n=1 or len(key))\u001b[39;00m\n\u001b[0;32m   3929\u001b[0m \u001b[38;5;124;03m        In case of a key partially contained in a MultiIndex, indicate\u001b[39;00m\n\u001b[0;32m   3930\u001b[0m \u001b[38;5;124;03m        which levels are used. Levels can be referred by label or position.\u001b[39;00m\n\u001b[0;32m   3931\u001b[0m \u001b[38;5;124;03m    drop_level : bool, default True\u001b[39;00m\n\u001b[0;32m   3932\u001b[0m \u001b[38;5;124;03m        If False, returns object with same levels as self.\u001b[39;00m\n\u001b[0;32m   3933\u001b[0m \n\u001b[0;32m   3934\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   3935\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   3936\u001b[0m \u001b[38;5;124;03m    Series or DataFrame\u001b[39;00m\n\u001b[0;32m   3937\u001b[0m \u001b[38;5;124;03m        Cross-section from the original Series or DataFrame\u001b[39;00m\n\u001b[0;32m   3938\u001b[0m \u001b[38;5;124;03m        corresponding to the selected index levels.\u001b[39;00m\n\u001b[0;32m   3939\u001b[0m \n\u001b[0;32m   3940\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[0;32m   3941\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   3942\u001b[0m \u001b[38;5;124;03m    DataFrame.loc : Access a group of rows and columns\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[38;5;124;03m        by label(s) or a boolean array.\u001b[39;00m\n\u001b[0;32m   3944\u001b[0m \u001b[38;5;124;03m    DataFrame.iloc : Purely integer-location based indexing\u001b[39;00m\n\u001b[0;32m   3945\u001b[0m \u001b[38;5;124;03m        for selection by position.\u001b[39;00m\n\u001b[0;32m   3946\u001b[0m \n\u001b[0;32m   3947\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[0;32m   3948\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[0;32m   3949\u001b[0m \u001b[38;5;124;03m    `xs` can not be used to set values.\u001b[39;00m\n\u001b[0;32m   3950\u001b[0m \n\u001b[0;32m   3951\u001b[0m \u001b[38;5;124;03m    MultiIndex Slicers is a generic way to get/set values on\u001b[39;00m\n\u001b[0;32m   3952\u001b[0m \u001b[38;5;124;03m    any level or levels.\u001b[39;00m\n\u001b[0;32m   3953\u001b[0m \u001b[38;5;124;03m    It is a superset of `xs` functionality, see\u001b[39;00m\n\u001b[0;32m   3954\u001b[0m \u001b[38;5;124;03m    :ref:`MultiIndex Slicers <advanced.mi_slicers>`.\u001b[39;00m\n\u001b[0;32m   3955\u001b[0m \n\u001b[0;32m   3956\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   3957\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   3958\u001b[0m \u001b[38;5;124;03m    >>> d = {'num_legs': [4, 4, 2, 2],\u001b[39;00m\n\u001b[0;32m   3959\u001b[0m \u001b[38;5;124;03m    ...      'num_wings': [0, 0, 2, 2],\u001b[39;00m\n\u001b[0;32m   3960\u001b[0m \u001b[38;5;124;03m    ...      'class': ['mammal', 'mammal', 'mammal', 'bird'],\u001b[39;00m\n\u001b[0;32m   3961\u001b[0m \u001b[38;5;124;03m    ...      'animal': ['cat', 'dog', 'bat', 'penguin'],\u001b[39;00m\n\u001b[0;32m   3962\u001b[0m \u001b[38;5;124;03m    ...      'locomotion': ['walks', 'walks', 'flies', 'walks']}\u001b[39;00m\n\u001b[0;32m   3963\u001b[0m \u001b[38;5;124;03m    >>> df = pd.DataFrame(data=d)\u001b[39;00m\n\u001b[0;32m   3964\u001b[0m \u001b[38;5;124;03m    >>> df = df.set_index(['class', 'animal', 'locomotion'])\u001b[39;00m\n\u001b[0;32m   3965\u001b[0m \u001b[38;5;124;03m    >>> df\u001b[39;00m\n\u001b[0;32m   3966\u001b[0m \u001b[38;5;124;03m                               num_legs  num_wings\u001b[39;00m\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;124;03m    class  animal  locomotion\u001b[39;00m\n\u001b[0;32m   3968\u001b[0m \u001b[38;5;124;03m    mammal cat     walks              4          0\u001b[39;00m\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;124;03m           dog     walks              4          0\u001b[39;00m\n\u001b[0;32m   3970\u001b[0m \u001b[38;5;124;03m           bat     flies              2          2\u001b[39;00m\n\u001b[0;32m   3971\u001b[0m \u001b[38;5;124;03m    bird   penguin walks              2          2\u001b[39;00m\n\u001b[0;32m   3972\u001b[0m \n\u001b[0;32m   3973\u001b[0m \u001b[38;5;124;03m    Get values at specified index\u001b[39;00m\n\u001b[0;32m   3974\u001b[0m \n\u001b[0;32m   3975\u001b[0m \u001b[38;5;124;03m    >>> df.xs('mammal')\u001b[39;00m\n\u001b[0;32m   3976\u001b[0m \u001b[38;5;124;03m                       num_legs  num_wings\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m \u001b[38;5;124;03m    animal locomotion\u001b[39;00m\n\u001b[0;32m   3978\u001b[0m \u001b[38;5;124;03m    cat    walks              4          0\u001b[39;00m\n\u001b[0;32m   3979\u001b[0m \u001b[38;5;124;03m    dog    walks              4          0\u001b[39;00m\n\u001b[0;32m   3980\u001b[0m \u001b[38;5;124;03m    bat    flies              2          2\u001b[39;00m\n\u001b[0;32m   3981\u001b[0m \n\u001b[0;32m   3982\u001b[0m \u001b[38;5;124;03m    Get values at several indexes\u001b[39;00m\n\u001b[0;32m   3983\u001b[0m \n\u001b[0;32m   3984\u001b[0m \u001b[38;5;124;03m    >>> df.xs(('mammal', 'dog'))\u001b[39;00m\n\u001b[0;32m   3985\u001b[0m \u001b[38;5;124;03m                num_legs  num_wings\u001b[39;00m\n\u001b[0;32m   3986\u001b[0m \u001b[38;5;124;03m    locomotion\u001b[39;00m\n\u001b[0;32m   3987\u001b[0m \u001b[38;5;124;03m    walks              4          0\u001b[39;00m\n\u001b[0;32m   3988\u001b[0m \n\u001b[0;32m   3989\u001b[0m \u001b[38;5;124;03m    Get values at specified index and level\u001b[39;00m\n\u001b[0;32m   3990\u001b[0m \n\u001b[0;32m   3991\u001b[0m \u001b[38;5;124;03m    >>> df.xs('cat', level=1)\u001b[39;00m\n\u001b[0;32m   3992\u001b[0m \u001b[38;5;124;03m                       num_legs  num_wings\u001b[39;00m\n\u001b[0;32m   3993\u001b[0m \u001b[38;5;124;03m    class  locomotion\u001b[39;00m\n\u001b[0;32m   3994\u001b[0m \u001b[38;5;124;03m    mammal walks              4          0\u001b[39;00m\n\u001b[0;32m   3995\u001b[0m \n\u001b[0;32m   3996\u001b[0m \u001b[38;5;124;03m    Get values at several indexes and levels\u001b[39;00m\n\u001b[0;32m   3997\u001b[0m \n\u001b[0;32m   3998\u001b[0m \u001b[38;5;124;03m    >>> df.xs(('bird', 'walks'),\u001b[39;00m\n\u001b[0;32m   3999\u001b[0m \u001b[38;5;124;03m    ...       level=[0, 'locomotion'])\u001b[39;00m\n\u001b[0;32m   4000\u001b[0m \u001b[38;5;124;03m             num_legs  num_wings\u001b[39;00m\n\u001b[0;32m   4001\u001b[0m \u001b[38;5;124;03m    animal\u001b[39;00m\n\u001b[0;32m   4002\u001b[0m \u001b[38;5;124;03m    penguin         2          2\u001b[39;00m\n\u001b[0;32m   4003\u001b[0m \n\u001b[0;32m   4004\u001b[0m \u001b[38;5;124;03m    Get values at specified column and axis\u001b[39;00m\n\u001b[0;32m   4005\u001b[0m \n\u001b[0;32m   4006\u001b[0m \u001b[38;5;124;03m    >>> df.xs('num_wings', axis=1)\u001b[39;00m\n\u001b[0;32m   4007\u001b[0m \u001b[38;5;124;03m    class   animal   locomotion\u001b[39;00m\n\u001b[0;32m   4008\u001b[0m \u001b[38;5;124;03m    mammal  cat      walks         0\u001b[39;00m\n\u001b[0;32m   4009\u001b[0m \u001b[38;5;124;03m            dog      walks         0\u001b[39;00m\n\u001b[0;32m   4010\u001b[0m \u001b[38;5;124;03m            bat      flies         2\u001b[39;00m\n\u001b[0;32m   4011\u001b[0m \u001b[38;5;124;03m    bird    penguin  walks         2\u001b[39;00m\n\u001b[0;32m   4012\u001b[0m \u001b[38;5;124;03m    Name: num_wings, dtype: int64\u001b[39;00m\n\u001b[0;32m   4013\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4014\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   4015\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:995\u001b[0m, in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     col_header \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m columns\u001b[38;5;241m.\u001b[39mnlevels\n\u001b[1;32m--> 995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m col_header \u001b[38;5;241m+\u001b[39m adjoined\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:89\u001b[0m, in \u001b[0;36mCSVFormatter.__init__\u001b[1;34m(self, formatter, path_or_buf, sep, cols, index_label, mode, encoding, errors, compression, quoting, lineterminator, chunksize, quotechar, date_format, doublequote, escapechar, storage_options)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator \u001b[38;5;241m=\u001b[39m lineterminator \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlinesep\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdate_format \u001b[38;5;241m=\u001b[39m date_format\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunksize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_chunksize(chunksize)\n",
      "File \u001b[1;32mc:\\Users\\karol\\GitHub\\mgr\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:161\u001b[0m, in \u001b[0;36mCSVFormatter._initialize_columns\u001b[1;34m(self, cols)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# update columns to include possible multiplicity of dupes\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# and make sure cols is just a list of labels\u001b[39;00m\n\u001b[0;32m    160\u001b[0m new_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_cols\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_native_types\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Index' object has no attribute '_format_native_types'"
     ]
    }
   ],
   "source": [
    "results_csv = \"classification_results_by_model.csv\"\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "results_df[\"mDeBERTa-v3\"] = results_df[\"mDeBERTa-v3\"].astype(str)\n",
    "\n",
    "\n",
    "# results_df.to_csv(results_csv, index=False, encoding=\"utf-8\")\n",
    "results_df.columns = [str(col) for col in results_df.columns]\n",
    "\n",
    "results_df.to_dict(orient=\"records\")\n",
    "results_df = pd.DataFrame(results_df)\n",
    "results_df.columns = [str(col) for col in results_df.columns]\n",
    "\n",
    "# Reset the index\n",
    "results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = \"classification_results_by_model.csv\"\n",
    "results_df.to_csv(csv_filename, index=False, encoding=\"utf-8\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
